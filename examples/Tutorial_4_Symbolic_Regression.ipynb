{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bingo Tutorial 4: Symbolic Regression\n",
    "\n",
    "## Goal: Given input data and output data, find the functional form of the equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acyclic Graphs\n",
    "\n",
    "Equations are represented as acyclic graphs in bingo.  The `AcyclicGraphChromosome` encapsulates a list of mathematical commands, performed in a set order, that define an equation.  These are called AGraphs in bingo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicit Training Data\n",
    "The way an AGraph's fitness is evaluated is whether or not it models some training data correctly. When both input and outputs are present in the training data, explicit regression is used.  This requires having some valid `ExplicitTrainingData`. `ExplicitTrainingData` requires x (input) and y (output) as numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from bingo.symbolic_regression import ExplicitTrainingData\n",
    "\n",
    "x = np.linspace(-10, 10, 30).reshape([-1, 1])\n",
    "y = x**2 + 3.5*x**3\n",
    "training_data = ExplicitTrainingData(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "plt.plot(training_data.x, training_data.y, 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AGraph Component Generator\n",
    "AGraphs also require a component generator to generate elements of an acylic graph object. It plays a similar role as `get_random_float` in the ZeroMinExample jupyter notebook.\n",
    "\n",
    "The dimension of the independent variable (x) is needed for the initialization of the component genrator.  After initialization, mathematical operators can be added to the generator.  These operators constitute the building blocks from which the AGraphs will be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bingo.symbolic_regression import ComponentGenerator\n",
    "\n",
    "component_generator = ComponentGenerator(input_x_dimension=x.shape[1])\n",
    "component_generator.add_operator(\"+\")\n",
    "component_generator.add_operator(\"-\")\n",
    "component_generator.add_operator(\"*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AGraph Generator\n",
    "The AGraph generator will use the component generator to generate `AGraphChromosome` individuals. In addion to the component generator, the desired size of the AGraphs is needed in initialization.  This size corresponds to the number of maximum number of commands possible in the AGraph. In other words, a larger size allows for more complex equations but comes at the cost of longer evaluation times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bingo.symbolic_regression import AGraphGenerator\n",
    "\n",
    "agraph_generator = AGraphGenerator(agraph_size=10, \n",
    "                                   component_generator=component_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agraph = agraph_generator()\n",
    "print(\"f(X_0) = \", agraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try rerunning the snippet above a few times to see some different equations produced by the genrator.  Note that X_0 represents the first dimension of the independent variable.  Also note that all numerical constants equal 1.0 unless local optimization is performed (more on this later)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AGraph Variation\n",
    "Set the the variation amongst the population per generation. \n",
    "AGraphCrossover is single-point.  Mutation contains several possible mutation strategies, most of which are single-point.  See documentation for more in depth description of mutation types and tailoring the mutation function. Both the crossover and mutation require the component generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bingo.symbolic_regression import AGraphCrossover\n",
    "from bingo.symbolic_regression import AGraphMutation\n",
    "\n",
    "crossover = AGraphCrossover(component_generator)\n",
    "mutation = AGraphMutation(component_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: Explicit Regression\n",
    "\n",
    "The type of regression that will be used is `ExplicitRegression` since the training data has both input and output data to train against. `ExplicitRegression` extends `FitnessFunction`; hence, may be passed to `ContinuousLocalOptimization` object as an argument. This is then passed to an `Evaluation` object which will run `ExplicitRegression` on all `AGraph` individuals.\n",
    "\n",
    "The `ContinuousLocalOptimization` is responsible for finding the best numerical constants for the given explicit regression.  The numerical constants are represented by \"?\" before local optimization has been performed (as you may have seen in the AGraph Generator section). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bingo.symbolic_regression import ExplicitRegression\n",
    "from bingo.local_optimizers.continuous_local_opt import ContinuousLocalOptimization\n",
    "from bingo.evaluation.evaluation import Evaluation\n",
    "\n",
    "fitness = ExplicitRegression(training_data=training_data)\n",
    "local_opt_fitness = ContinuousLocalOptimization(fitness, algorithm='lm')\n",
    "evaluator = Evaluation(local_opt_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(16)\n",
    "agraph = agraph_generator()\n",
    "print(\"Before local optimization: f(X_0) = \", agraph)\n",
    "print(\"                          fitness = \", fitness(agraph))\n",
    "_ = local_opt_fitness(agraph)\n",
    "print(\"After local optimization:  f(X_0) = \", agraph)\n",
    "print(\"                          fitness = \", fitness(agraph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AGraphs can be easily evaluated at a given x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agraph_y = agraph.evaluate_equation_at(training_data.x)\n",
    "\n",
    "plt.plot(training_data.x, training_data.y, 'ro')\n",
    "plt.plot(training_data.x, agraph_y, 'b-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age Fitness Evolutionary Algorithm\n",
    "\n",
    "The evoluaionary algorithm used in this example is `AgeFitnessEA`. This by default uses the `AgeFitnessSelection`. It also requires use of the `AGraphGenerator` in order to seed a random individuals.  The Age Fitness EA is used to combat premature convergence that can be seen in symbolic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bingo.evolutionary_algorithms.age_fitness import AgeFitnessEA\n",
    "\n",
    "POPULATION_SIZE = 32\n",
    "MUTATION_PROBABILITY = 0.4\n",
    "CROSSOVER_PROBABILITY = 0.4\n",
    "\n",
    "ea = AgeFitnessEA(evaluator, agraph_generator, crossover, mutation, \n",
    "                  MUTATION_PROBABILITY, CROSSOVER_PROBABILITY, POPULATION_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pareto Front\n",
    "\n",
    "A `ParetoFront` hall of fame object is useful in symbolic regression for tracking the best individuals, where fitness and equation complexity are both taken into consideration. The secondary key must be supplied to the `ParetoFront` object. The primary key can optionally be supplied instead of the default use of fitness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bingo.stats.pareto_front import ParetoFront\n",
    "\n",
    "def agraph_similarity(ag_1, ag_2):\n",
    "    \"\"\"a similarity metric between agraphs\"\"\"\n",
    "    return ag_1.fitness == ag_2.fitness and ag_1.get_complexity() == ag_2.get_complexity()\n",
    "\n",
    "pareto_front = ParetoFront(secondary_key=lambda ag: ag.get_complexity(),\n",
    "                           similarity_function=agraph_similarity) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution on an island\n",
    "Once an `Island` is set up, evolution occurs in the same way as described in earlier examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bingo.evolutionary_optimizers.island import Island\n",
    "np.random.seed(5)\n",
    "\n",
    "island = Island(ea, agraph_generator, POPULATION_SIZE, hall_of_fame=pareto_front)\n",
    "print(\"Best individual\\n f(X_0) =\", island.get_best_individual())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run until convergence. Print the best result. We store each best individual in a list and use this to observe how the best solution evolves over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERROR_TOLERANCE = 1e-6\n",
    "\n",
    "best_indv_values = []\n",
    "best_indv_values.append(island.get_best_individual())\n",
    "best_indv_gen = []\n",
    "best_indv_gen.append(island.generational_age)\n",
    "\n",
    "while island.get_best_fitness() > ERROR_TOLERANCE:\n",
    "    island.evolve(1)\n",
    "    best_indv = island.get_best_individual()\n",
    "    if best_indv.fitness < best_indv_values[-1].fitness:\n",
    "        best_indv_values.append(best_indv)\n",
    "        best_indv_gen.append(island.generational_age)\n",
    "\n",
    "print(\"Generation: \", island.generational_age)\n",
    "print(\"Success!\")\n",
    "print(\"Best individual\\n f(X_0) =\", island.get_best_individual())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the pareto then look at the Pareto front to see the tradeoff between fitness and complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" FITNESS   COMPLEXITY    EQUATION\")\n",
    "for member in pareto_front:\n",
    "    print(\"%.3e     \" % member.fitness, member.get_complexity(),\n",
    "          \"     f(X_0) =\", member)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animation of evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate_data(list_of_best_indv, list_of_best_gens, training_data):\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    num_frames = len(list_of_best_indv)\n",
    "    \n",
    "    x = training_data.x\n",
    "    y_actually = training_data.y\n",
    "    y = list_of_best_indv\n",
    "    g = list_of_best_gens\n",
    "    plt.plot(training_data.x, training_data.y, 'ro')\n",
    "    points, = ax.plot(x, y[0].evaluate_equation_at(x), 'b')\n",
    "    points.set_label('Generation :' + str(g[0]))\n",
    "    legend = ax.legend(loc='upper right', shadow=True)\n",
    "\n",
    "\n",
    "    def animate(i):\n",
    "        ax.collections.clear()\n",
    "        points.set_ydata(y[i].evaluate_equation_at(x))  # update the data\n",
    "        points.set_label('Generation :' + str(g[i]))\n",
    "        legend = ax.legend(loc='upper right')\n",
    "        return points, legend\n",
    "\n",
    "\n",
    "    # Init only required for blitting to give a clean slate.\n",
    "    def init():\n",
    "        points.set_ydata(np.ma.array(x, mask=True))\n",
    "        return points, points\n",
    "\n",
    "    plt.xlabel('x', fontsize=15)\n",
    "    plt.ylabel('y', fontsize=15)\n",
    "    plt.title(\"Best Individual in Island\", fontsize=12)\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "    ax.tick_params(axis='x', labelsize=12)\n",
    "    plt.close()\n",
    "\n",
    "    return animation.FuncAnimation(fig, animate, num_frames, init_func=init,\n",
    "                                interval=250, blit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "anim2 = animate_data(best_indv_values, best_indv_gen, training_data)\n",
    "HTML(anim2.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
