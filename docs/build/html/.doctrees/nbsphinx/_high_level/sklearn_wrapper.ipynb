{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0de0859",
   "metadata": {},
   "source": [
    "# Using the Scikit-Learn Wrapper\n",
    "\n",
    "A no-fuss way of using Bingo is by using the scikit-learn wrapper:\n",
    "`SymbolicRegressor`. Let's setup a test case to show how it works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237bafa2",
   "metadata": {},
   "source": [
    "## Setting Up the Regressor\n",
    "\n",
    "There are many options that can be set in `SymbolicRegressor`. Here we set some basic ones including\n",
    "`population_size` (the number of equations in a population), `stack_size` (the max number of nodes per equation), and `use_simplification`\n",
    "(whether to use simplification to speed up equation evaluation and for easier reading). You can see all of `SymbolicRegressor`'s\n",
    "options [here](../_apidocs/bingo.symbolic_regression.html#module-bingo.symbolic_regression.symbolic_regressor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9639ff1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bingo.symbolic_regression.symbolic_regressor import SymbolicRegressor\n",
    "regressor = SymbolicRegressor(population_size=100, stack_size=16,\n",
    "                              use_simplification=True,\n",
    "                              max_time=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f6886a",
   "metadata": {},
   "source": [
    "## Training Data\n",
    "Here we're just creating some dummy training data from the equation $5.0 X_0^2 + 3.5 X_0$. More on training data can be found\n",
    "in the [data formatting guide](data_formatting.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "02f73359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "X_0 = np.linspace(-10, 10, num=30).reshape((-1, 1))\n",
    "X = np.array(X_0)\n",
    "y = 5.0 * X_0 ** 2 + 3.5 * X_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1478f0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X, y)\n",
    "plt.xlabel(\"X_0\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Training Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a63161",
   "metadata": {},
   "source": [
    "## Fitting the Regressor\n",
    "\n",
    "Fitting is as simple as calling the `.fit()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef72682",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab9c04d",
   "metadata": {},
   "source": [
    "## Getting the Best Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb19e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_individual = regressor.get_best_individual()\n",
    "print(\"best individual is:\", best_individual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7573078",
   "metadata": {},
   "source": [
    "## Predicting Data with the Best Individual\n",
    "\n",
    "You can use the regressor's `.predict(X)` or\n",
    "the best_individual's `.predict(X)` to get\n",
    "its predictions for `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9a9c9105",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = regressor.predict(X)\n",
    "pred_y = best_individual.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c7ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y)\n",
    "plt.plot(X, pred_y, 'r')\n",
    "plt.xlabel(\"X_0\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend([\"Actual\", \"Predicted\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21beab0e",
   "metadata": {},
   "source": [
    "# Checking out the Pareto front\n",
    "The regressor has a `get_pareto_front()` function that can be used to investigate the tradeoff of fitness and complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fc88c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pareto_front = regressor.get_pareto_front()\n",
    "plt.step([i.complexity for i in pareto_front], \n",
    "         [max(i.fitness, 1e-20) for i in pareto_front], \n",
    "         'o-')\n",
    "for equ in pareto_front:\n",
    "    plt.text(equ.complexity, \n",
    "             (max(equ.fitness, 1e-20))*3, \n",
    "             str(equ))\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Complexity\")\n",
    "plt.ylabel(\"Fitness (MSE)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c66546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
